# The application of attention layer in speech-related tasks

Everything started with [the paper](https://arxiv.org/pdf/1706.03762.pdf). Attention mechanism was originally used in NLP tasks,
but due to the fact that both text and speech share the same characteristic of time series, it could also be employed in speech-related tasks as it is now.

In this post, we will briefly review its application in speech-related domains, such as keyword spotting, speech classification, speech recognition and more.

## [Soft Attention](https://arxiv.org/pdf/1803.10916.pdf)
