# Dataset and Dataloader 

> Dataset class in pytorch basically covers the data in a tuple and enables us to access the index of each data. this is necessary to create dataloader class which can be used to shuffle, apply Mini-Batch Gradient Descent and more.

## Custom Dataset

>If I had eight hours to build a machine learning model, I'd spend the first 6 hours preparing my dataset.

>Data preparation is paramount. Before building a model, become one with the data. Ask: What am I trying to do here?

_Source: @mrdbourke Twitter._

[The officical pytorch dataset & dataloader tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) is a good read.
There is also [a nice tutoiral on customising your own torchvision image dataset](https://www.learnpytorch.io
/04_pytorch_custom_datasets/).

I will mainly focus on _torch.utils.data.Dataset_ and _torch.utils.data.Dataloader_, and introduce how they are used in data preparation stage in a more _'my-way'_ way - that is, how I prepare audio fatures for training my speech ecogntion models.

Suppose we already have features extracted and stored piece-wise in `.npy` format. Let's kick off to the start!

**1. Prepare labels**
You can store your lables in `.txt` or `.csv` or `.npy`, whichever you like. Just remember that they need to be in a column, not a row.

```txt
T_1.npy 0
T_2.npy 0
...
F_1.npy 0
F_2.npy 1
...
```
If it's in `.csv` format, the separators would be `,` instead of a `\t`.

